{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNfd/D0AOgGnLXSRWkAl+X5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"c3fg4EeI66f5"},"outputs":[],"source":["import warnings\n","warnings.filterwarnings(\"ignore\")\n","import numpy as np # to use numpy arrays instead of lists\n","import pandas as pd # DataFrame (table)\n","import matplotlib.pyplot as plt # to plot\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, Dense, Flatten\n","from tensorflow.keras.layers import Conv1D, AveragePooling1D\n","from tensorflow.keras.callbacks import EarlyStopping\n","!pip install keras-tuner # Install keras-tuner\n","import keras_tuner as kt # Now import keras_tuner"],"metadata":{"id":"xb8w5kU47cJf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","from google.colab import drive\n","drive.mount('gdrive')"],"metadata":{"id":"elYpRqVe7cTE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def leeDatos():\n","\n","    dataSet = pd.read_csv(\"gdrive/MyDrive/Colab Notebooks/archive1.zip\", header=0, compression='zip')\n","\n","    return dataSet"],"metadata":{"id":"fACdscFyEZet"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def encodeData(dataSet=0):\n","    dataSet.dropna(inplace=True)\n","\n","    # Remove any 'neutral' ratings\n","    dataSet['sentiment'] = [\"negative\" if x == \"neutral\" else x for x in dataSet['sentiment']]\n","    dataSet['sent_analysis'] = np.where(dataSet['sentiment'] == \"positive\", 1, 0)\n","    datos = ['text', 'sent_analysis']\n","    misDatos = dataSet[datos]\n","\n","    return misDatos"],"metadata":{"id":"_0WfF2HIEam6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["datos = leeDatos()\n","print(datos)\n","print(\"\\n\")\n","\n","encodeDatos = encodeData(datos)\n","print(encodeDatos)\n","print(\"\\n\")\n","print(encodeDatos['sent_analysis'].mean())\n","print(\"\\n\")"],"metadata":{"id":"8XVxLXhwEdJH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ts_size = .25\n","trainSet, testSet = train_test_split(encodeDatos, test_size=ts_size, random_state=0)\n","print(trainSet)\n","print('trainSet shape: ', trainSet.shape)\n","print(testSet)\n","print('testSet shape: ', testSet.shape)\n","print(\"\\n\")"],"metadata":{"id":"MfLh0osOEtnS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vocab_size = 15000\n","max_length = 120\n","trunc_type='post'\n","padding_type='post'\n","oov_tok = \"<OOV>\"\n","\n","training_sentences= trainSet['text']\n","training_labels = trainSet['sent_analysis']\n","testing_sentences = testSet['text']\n","testing_labels = testSet['sent_analysis']"],"metadata":{"id":"u6nxWKNZFuhc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer =\n","\n","\"\"\"\n","\n","MISSING CODE HERE\n","\n","Complete the tokenizer\n","\n","\"\"\"\n","\n","word_index = tokenizer.word_index\n","\n","training_sequences = tokenizer.texts_to_sequences(training_sentences)\n","training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n","\n","testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n","testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"],"metadata":{"id":"_KhzJFAkE7gR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["training_padded = np.array(training_padded)\n","training_labels = np.array(training_labels)\n","testing_padded = np.array(testing_padded)\n","testing_labels = np.array(testing_labels)"],"metadata":{"id":"5j4ZwNBVE7pa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def model_builder(hp):\n","    vocab_size = 15000\n","    hp_embedding_dim = hp.Int('embedding_dim', min_value=4, max_value=48 , step=4)\n","    hp_max_length = hp.Int('input_length', min_value=60, max_value=140, step=5)\n","    hp_filters = hp.Int('filters', min_value=2, max_value=12, step=2)\n","    hp_kernel_size = hp.Int('kernel_size', min_value=2, max_value=6, step=1)\n","    hp_pool_size = hp.Int('pool_size', min_value=2, max_value=6, step=1)\n","    hp_activation_conv = hp.Choice('activation_conv', values=['linear', 'softplus', 'relu', 'sigmoid', 'tanh'])\n","    hp_activation_dense = hp.Choice('activation_dense', values=['linear', 'softplus', 'relu', 'sigmoid', 'tanh'])\n","    hp_optimizer = hp.Choice('optimizer', values=['adam', 'rmsprop'])\n","\n","    model = Sequential([\n","                      Embedding(vocab_size, hp_embedding_dim, input_length=hp_max_length),\n","                      Conv1D(filters=hp_filters, kernel_size=hp_kernel_size, activation=hp_activation_conv),\n","                      AveragePooling1D(pool_size=hp_pool_size),\n","                      Flatten(),\n","                      Dense(2, activation=hp_activation_dense),\n","                      Dense(1, activation='sigmoid', name=\"Outpul_layer\")\n","                      ])\n","\n","    opt = hp_optimizer\n","\n","\n","    \"\"\"\n","\n","    MISSING CODE HERE\n","\n","    Complete the model_builder function\n","\n","    \"\"\"\n","\n","\n","    return model"],"metadata":{"id":"zlFEaRkME70n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tuner = kt.Hyperband(model_builder,\n","                     objective='val_accuracy',\n","                     max_epochs=18,\n","                     factor=3,\n","                     )"],"metadata":{"id":"bCOSMx9TGwCq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["stop_early = EarlyStopping(monitor='val_loss', patience=5)"],"metadata":{"id":"ORtdQgpEGwi_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["validation_split_size = 0.35\n","num_epochs = 45\n","\n","tuner.search(training_padded,\n","             training_labels,\n","             validation_split=validation_split_size,\n","             epochs=num_epochs,\n","             callbacks=[stop_early],\n","             verbose=2)\n","\n","# Get the optimal hyperparameters\n","best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n","\n","print(f\"\"\"The hyperparameter search is complete.\n","The best 'input_length' for the embedding layer is {best_hps.get('input_length')}\n","\"\"\")"],"metadata":{"id":"YRJ2pvFtGwrl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model =\n","\n","\"\"\"\n","\n","MISSING CODE HERE\n","\n","Complete the model creation\n","\n","\"\"\""],"metadata":{"id":"WmQcsJHqHIwy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig = plt.figure()\n","fig.add_subplot(121)\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title(\"Loss vs Epochs\")\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['Training', 'Validation'], loc='upper right')\n","fig.add_subplot(122)\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title(\"Accuracy vs Epochs\")\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend(['Training', 'Validation'], loc='upper right')\n","plt.show()"],"metadata":{"id":"FJP1WimUHRH1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(model.evaluate(training_padded, training_labels, verbose=2))\n","print(\"\\n\")\n","\n","#### predict train data ######\n","df_train = pd.DataFrame()\n","df_train['real'] = training_labels\n","df_train['pred'] = model.predict(training_padded).reshape(1,len(training_padded))[0]\n","print(round(df_train))\n","print(model.evaluate(testing_padded,testing_labels, verbose=2))\n","print(\"\\n\")\n","\n","# test data\n","df_test = pd.DataFrame()\n","df_test['real'] = testing_labels\n","df_test['pred'] = model.predict(testing_padded).reshape(1,len(testing_padded))[0]\n","print(round(df_test))\n","\n","report = classification_report(testing_labels, round(df_test['pred']), output_dict=True)\n","df_report = pd.DataFrame(report).transpose()\n","print(df_report)\n","print(\"\\n\")"],"metadata":{"id":"zQM0huiTHwLM"},"execution_count":null,"outputs":[]}]}